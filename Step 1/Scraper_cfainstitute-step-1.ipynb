{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Selenium Setup for Google Colab\n",
        "\n",
        "## Introduction:\n",
        "This guide provides instructions for setting up Selenium on Google Colab, allowing you to automate browser interactions within the Colab environment.\n",
        "\n",
        "## Prerequisites:\n",
        "- Access to a Google Colab environment\n",
        "- Basic knowledge of running commands in Google Colab\n",
        "\n",
        "## Steps:\n",
        "\n",
        "### 1. Update System Packages:\n",
        "```bash\n",
        "sudo apt -y update\n"
      ],
      "metadata": {
        "id": "zvS3V7IqDX6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up for running selenium in Google Colab\n",
        "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G0JQWZbKMT1",
        "outputId": "3a76a7b2-e238-4448-a7c9-99c92c1b7e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connected to clou\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\u001b[33m\r0% [2 InRelease 12.7 kB/119 kB 11%] [Connecting to security.ubuntu.com (185.125\u001b[0m\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [2 InRelease 21.4 kB/119 kB 18%] [Connecting to security.ubuntu.com (185.125\u001b[0m\u001b[33m\r0% [2 InRelease 21.4 kB/119 kB 18%] [Connecting to security.ubuntu.com (185.125\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,834 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,343 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [50.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,742 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,463 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,796 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,070 kB]\n",
            "Fetched 9,532 kB in 2s (4,371 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "43 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.15).\n",
            "The following packages will be upgraded:\n",
            "  unzip\n",
            "1 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 175 kB of archives.\n",
            "After this operation, 1,024 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
            "Fetched 175 kB in 0s (978 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
            "Unpacking unzip (6.0-26ubuntu3.2) over (6.0-26ubuntu3.1) ...\n",
            "Setting up unzip (6.0-26ubuntu3.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "--2024-02-16 18:24:57--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.81, 91.189.91.82, 185.125.190.36, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-16 18:24:57 (282 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-02-16 18:24:57--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 74.125.196.91, 74.125.196.136, 74.125.196.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|74.125.196.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 106428268 (101M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 101.50M   276MB/s    in 0.4s    \n",
            "\n",
            "2024-02-16 18:24:58 (276 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [106428268/106428268]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 121753 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (121.0.6167.184-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-02-16 18:25:10--  https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.250.98.207, 142.250.97.207, 142.251.107.207, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.250.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7407250 (7.1M) [application/zip]\n",
            "Saving to: ‘/tmp/chromedriver_linux64.zip’\n",
            "\n",
            "chromedriver_linux6 100%[===================>]   7.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-02-16 18:25:10 (121 MB/s) - ‘/tmp/chromedriver_linux64.zip’ saved [7407250/7407250]\n",
            "\n",
            "Archive:  /tmp/chromedriver_linux64.zip\n",
            "  inflating: /tmp/chromedriver       \n",
            "  inflating: /tmp/LICENSE.chromedriver  \n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.17.2)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.9.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selenium Setup with Automatic Chromedriver Installation\n",
        "\n",
        "## Introduction:\n",
        "This guide provides instructions for setting up Selenium with automatic Chromedriver installation in Python, allowing you to automate browser interactions. With Chromedriver autoinstaller, you can ensure that the appropriate Chromedriver version is installed for your Chrome browser.\n",
        "\n",
        "## Prerequisites:\n",
        "- Python environment with pip installed\n",
        "- Basic knowledge of Python programming\n",
        "\n",
        "## Steps:\n",
        "\n",
        "### 1. Install Chromedriver Autoinstaller:\n",
        "```bash\n",
        "!pip install chromedriver-autoinstaller\n"
      ],
      "metadata": {
        "id": "dqTRKWpCDnjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromedriver-autoinstaller\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "\n",
        "# setup chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# set path to chromedriver as per your configuration\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# set up the webdriver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "# quit the driver\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS6_0SPFLNIJ",
        "outputId": "ebaa74c3-01b5-48a9-9642-02620c53a21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromedriver-autoinstaller in /usr/local/lib/python3.10/dist-packages (0.6.4)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping for Refresher Readings from CFA Institute Website\n",
        "\n",
        "## Introduction:\n",
        "This Python script demonstrates web scraping techniques to extract refresher reading details from the CFA Institute website. It utilizes Selenium for dynamic page interaction and Beautiful Soup for HTML parsing.\n",
        "\n",
        "## Prerequisites:\n",
        "- Python environment with necessary libraries installed (Selenium, BeautifulSoup, pandas)\n",
        "- Chrome browser installed\n",
        "\n",
        "## Setup:\n",
        "1. Install required libraries:\n",
        "```bash\n",
        "pip install selenium beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "id": "Qz6EMg0CEVRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Script Overview:**\n",
        "This script performs the following tasks:\n",
        "\n",
        "Initializes the WebDriver with headless Chrome options.\n",
        "Scrapes the main page of CFA Institute's refresher readings and navigates through pagination to extract reading titles and links.\n",
        "Extracts detailed information for each reading, including the topic, year, level, introduction, learning outcomes, summary, and overview.\n",
        "Structures the extracted data into a DataFrame and saves it to a CSV file."
      ],
      "metadata": {
        "id": "Yt0l1bd7EZYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXzXYSWaH6-B",
        "outputId": "50b811b4-ef4c-4a02-ee62-5d7dd1f79c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Title  \\\n",
            "0                                 Time-Series Analysis   \n",
            "1                               Credit Analysis Models   \n",
            "2              Introduction to Alternative Investments   \n",
            "3                                 Credit Default Swaps   \n",
            "4                       Valuation of Contingent Claims   \n",
            "..                                                 ...   \n",
            "219                  Fixed-Income Cash Flows and Types   \n",
            "220  Private Capital, Real Estate, Infrastructure, ...   \n",
            "221                  Extensions of Multiple Regression   \n",
            "222  Pricing and Valuation of Forward Contracts and...   \n",
            "223          Option Replication Using Put-Call Parity​   \n",
            "\n",
            "                       Topic  Year     Level  \\\n",
            "0       Quantitative Methods  2024  Level II   \n",
            "1               Fixed Income  2024  Level II   \n",
            "2    Alternative Investments  2023   Level I   \n",
            "3               Fixed Income  2024  Level II   \n",
            "4                Derivatives  2024  Level II   \n",
            "..                       ...   ...       ...   \n",
            "219             Fixed Income  2024   Level I   \n",
            "220  Alternative Investments  2023   Level I   \n",
            "221     Quantitative Methods  2024  Level II   \n",
            "222              Derivatives  2024   Level I   \n",
            "223              Derivatives  2023   Level I   \n",
            "\n",
            "                                          Introduction  \\\n",
            "0    Introduction\\nAs financial analysts, we often ...   \n",
            "1    Introduction\\nCredit analysis plays an importa...   \n",
            "2    Introduction\\nIn this section, we explain what...   \n",
            "3    Introduction\\nDerivative instruments in which ...   \n",
            "4    Introduction\\nA contingent claim is a derivati...   \n",
            "..                                                 ...   \n",
            "219                                                      \n",
            "220  Introduction\\nPrivate capital is the broad ter...   \n",
            "221                                                      \n",
            "222  Introduction\\nEarlier lessons introduced forwa...   \n",
            "223  Introduction\\nPrevious lessons examined the pa...   \n",
            "\n",
            "                                     Learning Outcomes  \\\n",
            "0    The member should be able to:\\n\\n\\n\\ncalculate...   \n",
            "1    The member should be able to:\\n\\nexplain expec...   \n",
            "2    The member should be able to:\\n\\ndescribe type...   \n",
            "3    The member should be able to:\\n\\ndescribe cred...   \n",
            "4    The member should be able to:\\n\\n\\ndescribe an...   \n",
            "..                                                 ...   \n",
            "219                                                      \n",
            "220  The member should be able to:\\n\\nexplain inves...   \n",
            "221  The member should be able to:\\n\\ndescribe infl...   \n",
            "222  The member should be able to:\\n\\nexplain how t...   \n",
            "223  The member should be able to:\\n\\nexplain put–c...   \n",
            "\n",
            "                                               Summary  \\\n",
            "0    The predicted trend value of a time series in ...   \n",
            "1    This reading has covered several important top...   \n",
            "2    This reading provides a comprehensive introduc...   \n",
            "3    A credit default swap (CDS) is a contract betw...   \n",
            "4    This reading on the valuation of contingent cl...   \n",
            "..                                                 ...   \n",
            "219                                                      \n",
            "220  Private capital is a broad term used for fundi...   \n",
            "221  Two kinds of observations may potentially infl...   \n",
            "222  A forward commitment price agreed upon at cont...   \n",
            "223  Put–call parity establishes a relationship tha...   \n",
            "\n",
            "                                              Overview  \n",
            "0                                                       \n",
            "1                                                       \n",
            "2                                                       \n",
            "3                                                       \n",
            "4                                                       \n",
            "..                                                 ...  \n",
            "219  A fixed-income instrument’s cash flows are det...  \n",
            "220                                                     \n",
            "221                                                     \n",
            "222                                                     \n",
            "223                                                     \n",
            "\n",
            "[224 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "\n",
        "def initialize_driver():\n",
        "    # setup chrome options\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    # set path to chromedriver as per your configuration\n",
        "    chromedriver_autoinstaller.install()\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    driver.maximize_window()\n",
        "    return driver\n",
        "\n",
        "def close_privacy_warning(driver):\n",
        "    close_button = driver.find_element(By.ID, \"closePrivacyWarning\")\n",
        "    close_button.click()\n",
        "\n",
        "def click_next_button(driver):\n",
        "    try:\n",
        "        next_button = driver.find_element(By.CLASS_NAME, \"coveo-pager-next\")\n",
        "        next_button.click()\n",
        "        time.sleep(5)\n",
        "        return driver\n",
        "    except NoSuchElementException:\n",
        "        return None\n",
        "\n",
        "def scrape(driver, refresher_readings_list):\n",
        "    time.sleep(5)  # Wait for the page to load\n",
        "    html_content = driver.page_source\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    titles = soup.find_all('h4', class_='coveo-title')\n",
        "    for title in titles:\n",
        "        link = title.find('a', class_='CoveoResultLink')['href']\n",
        "        reading = [title.text.strip(), link]\n",
        "        refresher_readings_list.append(reading)\n",
        "\n",
        "def get_reading_detail_data(driver, reading):\n",
        "    driver.get(reading[1])\n",
        "    time.sleep(5)\n",
        "    html_content = driver.page_source\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    meta_data = soup.find('div', class_=\"content-utility\")\n",
        "    span_elements = meta_data.find_all('span', class_=['content-utility-curriculum', 'content-utility-topic'])\n",
        "\n",
        "    data = {\n",
        "        \"topic\": \"\",\n",
        "        \"year\": \"\",\n",
        "        \"level\": \"\",\n",
        "        \"introduction\": \"\",\n",
        "        \"learning_outcomes\": \"\",\n",
        "        \"summary\": \"\",\n",
        "        \"overview\": \"\"\n",
        "    }\n",
        "\n",
        "    # Extract text content from selected span elements\n",
        "    if len(span_elements) >= 3:  # Ensure 'curriculum', 'topic', and 'level' span elements are present\n",
        "        data[\"year\"] = span_elements[0].text.strip().split()[0]\n",
        "        data[\"level\"] = span_elements[1].text.strip()\n",
        "        data[\"topic\"] = span_elements[2].text.strip()\n",
        "\n",
        "    # Extract data from other sections\n",
        "    headings = soup.find_all('h2', class_=\"article-section\")\n",
        "    for section in headings:\n",
        "        if section.text in ('Introduction', \"Learning Outcomes\", \"Summary\", \"Overview\"):\n",
        "            if section.text == \"Introduction\":\n",
        "                data[\"introduction\"] = section.findParent().text.strip()\n",
        "            elif section.text == \"Learning Outcomes\":\n",
        "                data[\"learning_outcomes\"] = section.find_next().text.strip()\n",
        "            elif section.text == \"Summary\":\n",
        "                data[\"summary\"] = section.find_next().text.strip()\n",
        "            elif section.text == \"Overview\":\n",
        "                data[\"overview\"] = section.find_next().text.strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def scrape_reading_detail(refresher_readings_list):\n",
        "    data_list = []\n",
        "    driver = initialize_driver()\n",
        "    for reading in refresher_readings_list:\n",
        "        reading_detail = get_reading_detail_data(driver, reading)\n",
        "        data_list.append({\n",
        "            'Title': reading[0],\n",
        "            'Topic': reading_detail['topic'],\n",
        "            'Year': reading_detail['year'],\n",
        "            'Level': reading_detail['level'],\n",
        "            'Introduction': reading_detail['introduction'],\n",
        "            'Learning Outcomes': reading_detail['learning_outcomes'],\n",
        "            'Summary': reading_detail['summary'],\n",
        "            'Overview': reading_detail['overview']\n",
        "        })\n",
        "    driver.quit()\n",
        "    df = pd.DataFrame(data_list)\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "    refresher_readings_list = []\n",
        "    driver = initialize_driver()\n",
        "    url = \"https://www.cfainstitute.org/en/membership/professional-development/refresher-readings#first=10&sort=%40refreadingcurriculumyear%20descending\"\n",
        "    driver.get(url)\n",
        "    close_privacy_warning(driver)\n",
        "    for page_num in range(23):\n",
        "        scrape(driver, refresher_readings_list)\n",
        "        driver = click_next_button(driver)\n",
        "        if driver is None:\n",
        "            break\n",
        "    df = scrape_reading_detail(refresher_readings_list)\n",
        "    print(df)\n",
        "    df.to_csv('refresher_readings.csv', index=False)\n",
        "    # driver.quit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mv42TiLEMGxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}